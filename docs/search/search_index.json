{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"NGSPipeDb: NGS pipelines & databases Author: Dr. Xuan Zhang Last update: 2021-05-8 Citation: NGSPipeDb: Automated pipelines for parallel processing of huge NGS data and databases generation. What can NGSPipeDb do NGSPipeDb is an automated pipeline for parallel processing of huge next generation sequencing (NGS) data and database generation using snakemake workflow which allows for ease of use, optimal speed, and a highly modular code that can be further added onto and customized by experienced users. It can be further divided into NGSPipe and NGSDb for individual usage. NGSPipe consists of a Snakefile ( ngspipe/rnaseq.snakefile.py , it includes some basic rules ngspipe/rule/*.snakefile.py ), conda environment files ( ngspipe/envs/*.yaml ), a configuration file ( ngspipe/config/rnaseq.config.yaml ), a set of python , R , Shell and Perl scripts ( ngspipe/scripts/*.py ), and a set of reStructuretext reports ( reports/*.rst ). It combines the use of several dozen omic-seq tools, suites, and packages to create a complete pipeline that takes RNA-seq analysis , resequcing analysis etc. from raw sequencing data all the way through alignment, quality control, unsupervised analyses, differential expression, and downstream pathway analysis. It is implemented such that alternative or similar analysis can be added or removed. The results are compiled in a simple and highly visual report containing the key figures to explain the analysis, and then compiles all of the relevant files, tables, and pictures into an easy to navigate folder. Table file such as csv, tsv, xlsx etc. It is based on snakemake and includes the following tools: * shovill (based on Spades) * QUAST v.5 (including BUSCO) * mash * fastp It will read untrimmed raw data from your illumina sequencing experiments as paired .fastq.gz-files. These are then trimmed, assembled and polished. Besides generating ready-for-use contigs, AQUAMIS will select the closest reference genome from NCBI RefSeq and produce an intuitive, detailed report on your data and assemblies to evaluate its reliability for further analyses. It relies on reference-based and reference-free measures such as coverage depth, gene content, genome completeness and contamination, assembly length and many more. Based on the experience from thousands of sequencing experiments, threshold sets for different species have been defined to detect potentially poor results. In addition, NGSDb has been outfitted with several recently published tools that allow for visualize and data share.can be convert to Sqlite3 format. The Django project and apps can be orgined by user defined. It is easy to share your data with a web inteface. a set of apps (such as home , igv , geneExpAtlas , efp brwose ). By default, the NGSPipeDb performs all the steps shown in the diagram below. However, advanced user, you can easily modify the Snakefile and the config.yaml and/or add \"custom rules\" to enable additional functions. Currently, transcript quantification with Salmon at the read-level or gene quantification by featureCounts can be activated. The first version handles RNA-Seq workflow. Workflows available: - RNA-seq - ChIP-seq - Resequencing TODO : NGSPipe miRNA scRNA-seq ATAC-seq NGSdb efp browser Contributing Please submit an issue to report bugs or ask questions. Please contribute bug fixes or new features with a pull request to this repository. If this does not help, please feel free to consult: * Xuan Zhang ( zhangxuan@xtbg.ac.cn ) Resources","title":"Getting start"},{"location":"#ngspipedb-ngs-pipelines-databases","text":"Author: Dr. Xuan Zhang Last update: 2021-05-8 Citation: NGSPipeDb: Automated pipelines for parallel processing of huge NGS data and databases generation.","title":"NGSPipeDb: NGS pipelines &amp; databases"},{"location":"#what-can-ngspipedb-do","text":"NGSPipeDb is an automated pipeline for parallel processing of huge next generation sequencing (NGS) data and database generation using snakemake workflow which allows for ease of use, optimal speed, and a highly modular code that can be further added onto and customized by experienced users. It can be further divided into NGSPipe and NGSDb for individual usage. NGSPipe consists of a Snakefile ( ngspipe/rnaseq.snakefile.py , it includes some basic rules ngspipe/rule/*.snakefile.py ), conda environment files ( ngspipe/envs/*.yaml ), a configuration file ( ngspipe/config/rnaseq.config.yaml ), a set of python , R , Shell and Perl scripts ( ngspipe/scripts/*.py ), and a set of reStructuretext reports ( reports/*.rst ). It combines the use of several dozen omic-seq tools, suites, and packages to create a complete pipeline that takes RNA-seq analysis , resequcing analysis etc. from raw sequencing data all the way through alignment, quality control, unsupervised analyses, differential expression, and downstream pathway analysis. It is implemented such that alternative or similar analysis can be added or removed. The results are compiled in a simple and highly visual report containing the key figures to explain the analysis, and then compiles all of the relevant files, tables, and pictures into an easy to navigate folder. Table file such as csv, tsv, xlsx etc. It is based on snakemake and includes the following tools: * shovill (based on Spades) * QUAST v.5 (including BUSCO) * mash * fastp It will read untrimmed raw data from your illumina sequencing experiments as paired .fastq.gz-files. These are then trimmed, assembled and polished. Besides generating ready-for-use contigs, AQUAMIS will select the closest reference genome from NCBI RefSeq and produce an intuitive, detailed report on your data and assemblies to evaluate its reliability for further analyses. It relies on reference-based and reference-free measures such as coverage depth, gene content, genome completeness and contamination, assembly length and many more. Based on the experience from thousands of sequencing experiments, threshold sets for different species have been defined to detect potentially poor results. In addition, NGSDb has been outfitted with several recently published tools that allow for visualize and data share.can be convert to Sqlite3 format. The Django project and apps can be orgined by user defined. It is easy to share your data with a web inteface. a set of apps (such as home , igv , geneExpAtlas , efp brwose ). By default, the NGSPipeDb performs all the steps shown in the diagram below. However, advanced user, you can easily modify the Snakefile and the config.yaml and/or add \"custom rules\" to enable additional functions. Currently, transcript quantification with Salmon at the read-level or gene quantification by featureCounts can be activated. The first version handles RNA-Seq workflow. Workflows available: - RNA-seq - ChIP-seq - Resequencing TODO : NGSPipe miRNA scRNA-seq ATAC-seq NGSdb efp browser","title":"What can NGSPipeDb do "},{"location":"#contributing","text":"Please submit an issue to report bugs or ask questions. Please contribute bug fixes or new features with a pull request to this repository. If this does not help, please feel free to consult: * Xuan Zhang ( zhangxuan@xtbg.ac.cn )","title":"Contributing"},{"location":"#resources","text":"","title":"Resources"},{"location":"NGSDb/","text":"NGSDb one step to view the NGSPipe RNA-Seq analysis results in a browser bash ngspipe/scripts/one_step_view_database.sh test Now you can viste your website on http://127.0.0.1:8000. All result are stored in results . - Example of report . - Example of database . Step-by-step to generate database with test data","title":"NGSDb with multi genomes"},{"location":"NGSDb/#ngsdb","text":"","title":"NGSDb"},{"location":"NGSDb/#one-step-to-view-the-ngspipe-rna-seq-analysis-results-in-a-browser","text":"bash ngspipe/scripts/one_step_view_database.sh test Now you can viste your website on http://127.0.0.1:8000. All result are stored in results . - Example of report . - Example of database .","title":"one step to view the NGSPipe RNA-Seq analysis results in a browser"},{"location":"NGSDb/#step-by-step-to-generate-database-with-test-data","text":"","title":"Step-by-step to generate database with test data "},{"location":"NGSPipe-ChIP-seq/","text":"chip-seq analysis","title":"NGSPipe ChIP-seq"},{"location":"NGSPipe-ChIP-seq/#chip-seq-analysis","text":"","title":"chip-seq analysis"},{"location":"NGSPipe-resequecing/","text":"resequcing analysis","title":"NGSPipe resequecing"},{"location":"NGSPipe-resequecing/#resequcing-analysis","text":"","title":"resequcing analysis"},{"location":"NGSPipe-trinity/","text":"denovo RNA-Seq analysis step-by-step run RNA-Seq analysis on testdata 1. pre-prepare download source code Install wget and git Install Miniconda3 Download NGSPipeDb source code Modify the project name and enter the project directory. mv NGSPipeDb species_sample_transcript_analysis_by_NGSPipeDb cd species_sample_transcript_analysis_by_NGSPipeDb 2. create conda envirenment conda bioconda lastest trinity version on macos is vdate.2011_11_26; on linux is v2.12.0 \u5efa\u8bae\u8fd8\u662f\u5728linux\u4e0a\u8fd0\u884ctrinity mamba create -n ngspipe-trinity python = 3 .8 -c conda-forge -y mamba env update -n ngspipe-trinity --file ngspipe/envs/requirements_ngspipe_trinity.yaml --prune conda activate ngspipe-trinity 3. download testdata mkdir -p testdata && cd testdata wget http://www.liu-lab.com/ngspipedb/testdata/control_R1.fq.gz wget http://www.liu-lab.com/ngspipedb/testdata/treated_R1.fq.gz wget http://www.liu-lab.com/ngspipedb/testdata/control_R2.fq.gz wget http://www.liu-lab.com/ngspipedb/testdata/treated_R2.fq.gz wget http://www.liu-lab.com/ngspipedb/testdata/chr19.fa.gz gunzip chr19.fa.gz wget http://www.liu-lab.com/ngspipedb/testdata/samples_resequencing.xls -O samples_chipseq.xls cd .. 4. run snakemake snakemake -s ngspipe/1.4.rnaseq_analysis_denovo_trinity.Snakefile.py --configfile ngspipe/config/trinity.config.yaml -p -j 1 -n","title":"denovo RNA-Seq analysis"},{"location":"NGSPipe-trinity/#denovo-rna-seq-analysis","text":"","title":"denovo RNA-Seq analysis"},{"location":"NGSPipe-trinity/#step-by-step-run-rna-seq-analysis-on-testdata","text":"","title":"step-by-step run RNA-Seq analysis on testdata"},{"location":"NGSPipe-trinity/#1-pre-prepare-download-source-code","text":"Install wget and git Install Miniconda3 Download NGSPipeDb source code Modify the project name and enter the project directory. mv NGSPipeDb species_sample_transcript_analysis_by_NGSPipeDb cd species_sample_transcript_analysis_by_NGSPipeDb","title":"1. pre-prepare download source code"},{"location":"NGSPipe-trinity/#2-create-conda-envirenment","text":"conda bioconda lastest trinity version on macos is vdate.2011_11_26; on linux is v2.12.0 \u5efa\u8bae\u8fd8\u662f\u5728linux\u4e0a\u8fd0\u884ctrinity mamba create -n ngspipe-trinity python = 3 .8 -c conda-forge -y mamba env update -n ngspipe-trinity --file ngspipe/envs/requirements_ngspipe_trinity.yaml --prune conda activate ngspipe-trinity","title":"2. create conda envirenment"},{"location":"NGSPipe-trinity/#3-download-testdata","text":"mkdir -p testdata && cd testdata wget http://www.liu-lab.com/ngspipedb/testdata/control_R1.fq.gz wget http://www.liu-lab.com/ngspipedb/testdata/treated_R1.fq.gz wget http://www.liu-lab.com/ngspipedb/testdata/control_R2.fq.gz wget http://www.liu-lab.com/ngspipedb/testdata/treated_R2.fq.gz wget http://www.liu-lab.com/ngspipedb/testdata/chr19.fa.gz gunzip chr19.fa.gz wget http://www.liu-lab.com/ngspipedb/testdata/samples_resequencing.xls -O samples_chipseq.xls cd ..","title":"3. download testdata"},{"location":"NGSPipe-trinity/#4-run-snakemake","text":"snakemake -s ngspipe/1.4.rnaseq_analysis_denovo_trinity.Snakefile.py --configfile ngspipe/config/trinity.config.yaml -p -j 1 -n","title":"4. run snakemake"},{"location":"NGSPipeDb/","text":"NGSPipeDb - NGS pipeline and database Author: Dr. Xuan Zhang Last update: 2021-01-20 Citation: NGSPipeDb: An automated pipeline for parallel processing of huge NGS data and database generation. Table of Contents: Introduction to NGSPipeDb System requirements Anatomy of a NGSPipeDb project Basics: An example execution of RNA-seq analysis with test data Advance: An example execution of RNA-seq analysis with custome data Reproducibility Troubleshooting Introduction to NGSPipeDb NGSPipeDb is an automated pipeline for parallel processing of huge next generation sequencing (NGS) data and database generation using snakemake workflow which allows for ease of use, optimal speed, and a highly modular code that can be further added onto and customized by experienced users. It can be further divided into NGSPipe and NGSDb for individual usage. NGSPipe consists of a Snakefile ( ngspipe/rnaseq.snakefile.py , it includes some basic rules ngspipe/rule/*.snakefile.py ), conda environment files ( ngspipe/envs/*.yaml ), a configuration file ( ngspipe/config/rnaseq.config.yaml ), a set of python , R , Shell and Perl scripts ( ngspipe/scripts/*.py ), and a set of reStructuretext reports ( reports/*.rst ). It combines the use of several dozen omic-seq tools, suites, and packages to create a complete pipeline that takes RNA-seq analysis , resequcing analysis etc. from raw sequencing data all the way through alignment, quality control, unsupervised analyses, differential expression, and downstream pathway analysis. It is implemented such that alternative or similar analysis can be added or removed. The results are compiled in a simple and highly visual report containing the key figures to explain the analysis, and then compiles all of the relevant files, tables, and pictures into an easy to navigate folder. Table file such as csv, tsv, xlsx etc. It is based on snakemake and includes the following tools: * shovill (based on Spades) * QUAST v.5 (including BUSCO) * mash * fastp It will read untrimmed raw data from your illumina sequencing experiments as paired .fastq.gz-files. These are then trimmed, assembled and polished. Besides generating ready-for-use contigs, AQUAMIS will select the closest reference genome from NCBI RefSeq and produce an intuitive, detailed report on your data and assemblies to evaluate its reliability for further analyses. It relies on reference-based and reference-free measures such as coverage depth, gene content, genome completeness and contamination, assembly length and many more. Based on the experience from thousands of sequencing experiments, threshold sets for different species have been defined to detect potentially poor results. In addition, NGSDb has been outfitted with several recently published tools that allow for visualize and data share.can be convert to Sqlite3 format. The Django project and apps can be orgined by user defined. It is easy to share your data with a web inteface. a set of apps (such as home , igv , geneExpAtlas , efp brwose ). By default, the NGSPipeDb performs all the steps shown in the diagram below. However, advanced user, you can easily modify the Snakefile and the config.yaml and/or add \"custom rules\" to enable additional functions. Currently, transcript quantification with Salmon at the read-level or gene quantification by featureCounts can be activated. The first version handles RNA-Seq workflow. Workflows available: - RNA-seq - ChIP-seq - Resequencing TODO : NGSPipe miRNA scRNA-seq ATAC-seq NGSdb efp browser System requirements Building NGSPipeDb and running the examples require Linux, MacOS or Windows Subsystem for Linux ( WSL ) on Win10. Other Unix environments will probably work but have not been tested. The test data can be run on personal computer, for example 8G memeory. Some of the tools that NGSPipeDb uses, e.g. STAR and cufflinks are very memory intensive programs. Therefore we recommend the following system requirements for NGSPipeDb: We recommend that you run NGSPipeDb on a server that has at least 30GB of ram. This will allow for a single-threaded NGSPipeDb run (on mouse samples). We recommend that you have at least 128GB of ram and at least a 4-core CPU if you want to run NGSPipeDb in multi-threaded mode (which will speedup the workflow significantly). Our own servers have 256GB of ram and 32 cores. Anatomy of a NGSPipeDb project It is recommended to download NGSPipeDb source and change its name to your project name (For example: mv NGSPipeDb mouse_transcriptome_analysis ), it may looks like the following structure (command: tree -d -L 2 mouse_transcriptome_analysis ): mouse_transcriptome_analysis \u251c\u2500\u2500 README.md \u251c\u2500\u2500 ngsdb \u2502 \u251c\u2500\u2500 blastplus \u2502 \u251c\u2500\u2500 db.sqlite3 \u2502 \u251c\u2500\u2500 geneAnno \u2502 \u251c\u2500\u2500 geneExpAtlas \u2502 \u251c\u2500\u2500 home \u2502 \u251c\u2500\u2500 igv \u2502 \u251c\u2500\u2500 manage.py \u2502 \u2514\u2500\u2500 ngsdb \u251c\u2500\u2500 ngspipe \u2502 \u251c\u2500\u2500 config \u2502 \u251c\u2500\u2500 db_generate.Snakefile.py \u2502 \u251c\u2500\u2500 envs \u2502 \u251c\u2500\u2500 imgs \u2502 \u251c\u2500\u2500 notebooks \u2502 \u251c\u2500\u2500 reports \u2502 \u251c\u2500\u2500 rnaseq_analysis.Snakefile.py \u2502 \u251c\u2500\u2500 rules \u2502 \u2514\u2500\u2500 scripts \u251c\u2500\u2500 results \u2502 \u251c\u2500\u2500 report \u2502 \u251c\u2500\u2500 resultdata \u2502 \u2514\u2500\u2500 sqlite3 \u2514\u2500\u2500 testdata The workflow code goes into a subfolder ngspipe , while the configuration is stored in a subfolder config . Inside of the workflow subfolder, the central Snakefile marks the entrypoint of the workflow. In addition to the central Snakefile, rules are stored in a modular way, using the optional subfolder ngspipe/rules . Further, scripts are stored in a subfolder workflow/scripts and notebooks in a subfolder workflow/notebooks . Conda environments are stored in a subfolder workflow/envs . Finally, report caption files are stored in workflow/report . The database code goes into a subfolder ngsdb , while the manage.py is ngsdb's command-line utility for administrative tasks. A golabl setting file is stored under ngsdb/ngsdb , such as ngsdb/ngsdb/setting.py and ngsdb/ngsdb/urls.py . Many ngsdb function module take a app name. For example, if your INSTALLED_APPS in ngsdb/ngsdb/setting.py contains the string 'igv', the database will contain a page of IGV genome browser. All output files generated in the workflow should be stored under results/result , unless they are rather retrieved report, in which case they should be stored under results/report . The latter subfolder results/sqlite3 contains Sqlite3 kind file that shall be used by ngsdb. Basics: An example execution of RNA-seq analysis with test data Advance: An example execution of RNA-seq analysis with custome data Reproducibility conda\u73af\u5883\u514b\u9686conda create -n ngspipedb_py38_conda_env \u2013clone ./ngspipedb_py38_conda_env/ use conda env export cd NGSPipeDB_source_code # export to yaml conda env export --no-builds -p ./ngspipedb_py38_conda_env >ngspipedb_py38_conda_env.yaml use conda pack \u7528\u2013use-conda\u8fd9\u4e2a\u53c2\u6570\u7684\u8bdd\uff0c\u56e0\u4e3a\u6240\u6709\u8f6f\u4ef6\u7684\u73af\u5883\u90fd\u662f\u5355\u72ec\u7684\uff0c\u6240\u6709conda\u5b89\u88c5\u7684\u65f6\u5019\u4e0d\u4f1a\u51fa\u9519\uff0c\u90a3\u4e48\u5982\u679c\u5df2\u7ecf\u4e0b\u8f7d\u5b89\u88c5\u597d\u4e86\u73af\u5883\uff0c\u7528\u8fd9\u79cd\u65b9\u5f0f\u5982\u4f55\u4f7f\u7528\uff1f\u9ed8\u8ba4\u7684\u73af\u5883\u662f.snakemake\u6587\u4ef6\u5939\u4e0b\uff0c\u5982\u4f55\u6307\u5b9a\uff1f \u7528\u4e0a\u9762\u7684\u65b9\u5f0f\u597d\u5b89\u88c5\uff0c\u4e0d\u4f1a\u51fa\u9519\uff0c\u4f46\u662f\u4f1a\u5bfc\u81f4\u6587\u4ef6\u5f88\u5927\uff0c\u591a\u5927\uff1f \u662f\u5426\u80fd\u628a\u4e00\u73af\u5883\u5206\u6210\u4e24\u90e8\u5206\uff1f\u4e00\u90e8\u5206\u8f6f\u4ef6\u96c6\u5408\u8d77\u6765\u53d8\u6210\u4e00\u4e2a\u5927\u73af\u5883\uff0c\u53e6\u4e00\u90e8\u5206\u8f6f\u4ef6\u5c31\u7528\u2013use-conda\u73af\u5883\u5355\u72ec\u6307\u5b9a\uff0c\u4f46\u662f\u8fd9\u4e24\u79cd\u65b9\u5f0f\u80fd\u7ed3\u5408\u5230\u4e00\u8d77\u7528\u5417\uff1f # pack cd NGSPipeDB_source_code mamba install -c conda-forge conda-pack conda pack -p ./ngspipedb_py38_conda_env -o ngspipedb_py38_conda_env_osx64.tar.gz # unpack on another machine mkdir -p ngspipedb_py38_conda_env tar -xzf ngspipedb_py38_conda_env_osx64.tar.gz -C ngspipedb_py38_conda_env source activate ./ngspipedb_py38_conda_env conda-unpack conda config \u2013add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config \u2013add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config \u2013add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ conda config \u2013add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/ activate base and set miniconda path conda init Conda Prompt Customization conda config \u2013set env_prompt '({name}) ' source ~/.bashrc update conda, (optional) conda update conda create conda visual environment, python version, snakemake version, env directory,django version conda create -p ngspipedb_py38_conda_env python=3.8 activate conda env conda activate ./ngspipedb_py38_conda_env install mamba to make install software faster. conda install mamba -c conda-forge update some bioinformatics tools we will use bellow. mamba env update \u2013prefix ./ngspipedb_py38_conda_env/ \u2013file requirement.yaml \u2013prune you can exit virtual environment by conda deactivate https://wooey.readthedocs.io/en/latest/install.html \u2013conda-frontend mamba \u9009\u62e9\u66f4\u5feb\u4e00\u70b9\u7684mamba \u2013conda-create-envs-only \u53ea\u521b\u5efa\u73af\u5883\uff0c\u7136\u540e\u9000\u51fa\uff0c\u4e0d\u8fd0\u884c\u7a0b\u5e8f\uff0c\u8fd9\u4e2a\u53ef\u4ee5\u7528\u6765\u4e13\u95e8\u6d4b\u8bd5\u73af\u5883 mac\u4e0a\u7684conda\u73af\u5883\u597d\u50cf\u6ca1\u6709linux\u4e0a\u9762\u90a3\u4e48\u597d\u7528\uff0c\u7279\u522b\u662fanaconda\u521b\u5efa\u7684\u73af\u5883 \u2013conda-prefix \u6307\u5b9aconda\u73af\u5883\u5b89\u88c5\u5730\u5740 \u6e05\u7406conda\u5b89\u88c5\u5305\u548c\u7f13\u5b58 snakemake -s ngspipe/db_generate.Snakefile.py \u2013use-conda \u2013conda-prefix condaEnvSplit -p -j1 Simplest is just abandon the \u2013use-conda flag, as suggested in the answer. Alternatively, you could make a container that has the env pre-created and configured, then use \u2013use-singularity. Or, if the post-installation can be automated, one could build a custom Conda package that runs some post-linking scripts. Sorry I seem to have missed your comment! snakemake \u5982\u4f55\u8fd0\u884c\u5355\u4e2a\u7a0b\u5e8f\uff1f\u8fd9\u4e2a\u4e5f\u5f88\u6709\u7528 \u57fa\u56e0\u7684\u547d\u4ee4\uff0c\u50cfdkango\u8fd9\u6837\u7684\u547d\u4ee4\u5728\u5f88\u591arules\u4e2d\u90fd\u6709\uff0c\u6240\u6709\u6bd4\u5982\u6709\u4e2a\u9876\u5c42\u7684\u73af\u5883\u4e2d\u5b89\u88c5\u4e86django Troubleshooting Ngsdb.yaml+wooey Python=3.8 samtools clustergrammer Pip install wooey pip install pandas==0.25.3 Contributing Please submit an issue to report bugs or ask questions. Please contribute bug fixes or new features with a pull request to this repository. If this does not help, please feel free to consult: * Xuan Zhang ( zhangxuan@xtbg.ac.cn ) or","title":"NGSPipeDb Tutorial"},{"location":"NGSPipeDb/#ngspipedb-ngs-pipeline-and-database","text":"Author: Dr. Xuan Zhang Last update: 2021-01-20 Citation: NGSPipeDb: An automated pipeline for parallel processing of huge NGS data and database generation. Table of Contents: Introduction to NGSPipeDb System requirements Anatomy of a NGSPipeDb project Basics: An example execution of RNA-seq analysis with test data Advance: An example execution of RNA-seq analysis with custome data Reproducibility Troubleshooting","title":"NGSPipeDb - NGS pipeline and database"},{"location":"NGSPipeDb/#introduction-to-ngspipedb","text":"NGSPipeDb is an automated pipeline for parallel processing of huge next generation sequencing (NGS) data and database generation using snakemake workflow which allows for ease of use, optimal speed, and a highly modular code that can be further added onto and customized by experienced users. It can be further divided into NGSPipe and NGSDb for individual usage. NGSPipe consists of a Snakefile ( ngspipe/rnaseq.snakefile.py , it includes some basic rules ngspipe/rule/*.snakefile.py ), conda environment files ( ngspipe/envs/*.yaml ), a configuration file ( ngspipe/config/rnaseq.config.yaml ), a set of python , R , Shell and Perl scripts ( ngspipe/scripts/*.py ), and a set of reStructuretext reports ( reports/*.rst ). It combines the use of several dozen omic-seq tools, suites, and packages to create a complete pipeline that takes RNA-seq analysis , resequcing analysis etc. from raw sequencing data all the way through alignment, quality control, unsupervised analyses, differential expression, and downstream pathway analysis. It is implemented such that alternative or similar analysis can be added or removed. The results are compiled in a simple and highly visual report containing the key figures to explain the analysis, and then compiles all of the relevant files, tables, and pictures into an easy to navigate folder. Table file such as csv, tsv, xlsx etc. It is based on snakemake and includes the following tools: * shovill (based on Spades) * QUAST v.5 (including BUSCO) * mash * fastp It will read untrimmed raw data from your illumina sequencing experiments as paired .fastq.gz-files. These are then trimmed, assembled and polished. Besides generating ready-for-use contigs, AQUAMIS will select the closest reference genome from NCBI RefSeq and produce an intuitive, detailed report on your data and assemblies to evaluate its reliability for further analyses. It relies on reference-based and reference-free measures such as coverage depth, gene content, genome completeness and contamination, assembly length and many more. Based on the experience from thousands of sequencing experiments, threshold sets for different species have been defined to detect potentially poor results. In addition, NGSDb has been outfitted with several recently published tools that allow for visualize and data share.can be convert to Sqlite3 format. The Django project and apps can be orgined by user defined. It is easy to share your data with a web inteface. a set of apps (such as home , igv , geneExpAtlas , efp brwose ). By default, the NGSPipeDb performs all the steps shown in the diagram below. However, advanced user, you can easily modify the Snakefile and the config.yaml and/or add \"custom rules\" to enable additional functions. Currently, transcript quantification with Salmon at the read-level or gene quantification by featureCounts can be activated. The first version handles RNA-Seq workflow. Workflows available: - RNA-seq - ChIP-seq - Resequencing TODO : NGSPipe miRNA scRNA-seq ATAC-seq NGSdb efp browser","title":"Introduction to NGSPipeDb "},{"location":"NGSPipeDb/#system-requirements","text":"Building NGSPipeDb and running the examples require Linux, MacOS or Windows Subsystem for Linux ( WSL ) on Win10. Other Unix environments will probably work but have not been tested. The test data can be run on personal computer, for example 8G memeory. Some of the tools that NGSPipeDb uses, e.g. STAR and cufflinks are very memory intensive programs. Therefore we recommend the following system requirements for NGSPipeDb: We recommend that you run NGSPipeDb on a server that has at least 30GB of ram. This will allow for a single-threaded NGSPipeDb run (on mouse samples). We recommend that you have at least 128GB of ram and at least a 4-core CPU if you want to run NGSPipeDb in multi-threaded mode (which will speedup the workflow significantly). Our own servers have 256GB of ram and 32 cores.","title":"System requirements "},{"location":"NGSPipeDb/#anatomy-of-a-ngspipedb-project","text":"It is recommended to download NGSPipeDb source and change its name to your project name (For example: mv NGSPipeDb mouse_transcriptome_analysis ), it may looks like the following structure (command: tree -d -L 2 mouse_transcriptome_analysis ): mouse_transcriptome_analysis \u251c\u2500\u2500 README.md \u251c\u2500\u2500 ngsdb \u2502 \u251c\u2500\u2500 blastplus \u2502 \u251c\u2500\u2500 db.sqlite3 \u2502 \u251c\u2500\u2500 geneAnno \u2502 \u251c\u2500\u2500 geneExpAtlas \u2502 \u251c\u2500\u2500 home \u2502 \u251c\u2500\u2500 igv \u2502 \u251c\u2500\u2500 manage.py \u2502 \u2514\u2500\u2500 ngsdb \u251c\u2500\u2500 ngspipe \u2502 \u251c\u2500\u2500 config \u2502 \u251c\u2500\u2500 db_generate.Snakefile.py \u2502 \u251c\u2500\u2500 envs \u2502 \u251c\u2500\u2500 imgs \u2502 \u251c\u2500\u2500 notebooks \u2502 \u251c\u2500\u2500 reports \u2502 \u251c\u2500\u2500 rnaseq_analysis.Snakefile.py \u2502 \u251c\u2500\u2500 rules \u2502 \u2514\u2500\u2500 scripts \u251c\u2500\u2500 results \u2502 \u251c\u2500\u2500 report \u2502 \u251c\u2500\u2500 resultdata \u2502 \u2514\u2500\u2500 sqlite3 \u2514\u2500\u2500 testdata The workflow code goes into a subfolder ngspipe , while the configuration is stored in a subfolder config . Inside of the workflow subfolder, the central Snakefile marks the entrypoint of the workflow. In addition to the central Snakefile, rules are stored in a modular way, using the optional subfolder ngspipe/rules . Further, scripts are stored in a subfolder workflow/scripts and notebooks in a subfolder workflow/notebooks . Conda environments are stored in a subfolder workflow/envs . Finally, report caption files are stored in workflow/report . The database code goes into a subfolder ngsdb , while the manage.py is ngsdb's command-line utility for administrative tasks. A golabl setting file is stored under ngsdb/ngsdb , such as ngsdb/ngsdb/setting.py and ngsdb/ngsdb/urls.py . Many ngsdb function module take a app name. For example, if your INSTALLED_APPS in ngsdb/ngsdb/setting.py contains the string 'igv', the database will contain a page of IGV genome browser. All output files generated in the workflow should be stored under results/result , unless they are rather retrieved report, in which case they should be stored under results/report . The latter subfolder results/sqlite3 contains Sqlite3 kind file that shall be used by ngsdb.","title":"Anatomy of a NGSPipeDb project "},{"location":"NGSPipeDb/#basics-an-example-execution-of-rna-seq-analysis-with-test-data","text":"","title":"Basics: An example execution of RNA-seq analysis with test data"},{"location":"NGSPipeDb/#advance-an-example-execution-of-rna-seq-analysis-with-custome-data","text":"","title":"Advance: An example execution of RNA-seq analysis with custome data"},{"location":"NGSPipeDb/#reproducibility","text":"conda\u73af\u5883\u514b\u9686conda create -n ngspipedb_py38_conda_env \u2013clone ./ngspipedb_py38_conda_env/ use conda env export cd NGSPipeDB_source_code # export to yaml conda env export --no-builds -p ./ngspipedb_py38_conda_env >ngspipedb_py38_conda_env.yaml use conda pack \u7528\u2013use-conda\u8fd9\u4e2a\u53c2\u6570\u7684\u8bdd\uff0c\u56e0\u4e3a\u6240\u6709\u8f6f\u4ef6\u7684\u73af\u5883\u90fd\u662f\u5355\u72ec\u7684\uff0c\u6240\u6709conda\u5b89\u88c5\u7684\u65f6\u5019\u4e0d\u4f1a\u51fa\u9519\uff0c\u90a3\u4e48\u5982\u679c\u5df2\u7ecf\u4e0b\u8f7d\u5b89\u88c5\u597d\u4e86\u73af\u5883\uff0c\u7528\u8fd9\u79cd\u65b9\u5f0f\u5982\u4f55\u4f7f\u7528\uff1f\u9ed8\u8ba4\u7684\u73af\u5883\u662f.snakemake\u6587\u4ef6\u5939\u4e0b\uff0c\u5982\u4f55\u6307\u5b9a\uff1f \u7528\u4e0a\u9762\u7684\u65b9\u5f0f\u597d\u5b89\u88c5\uff0c\u4e0d\u4f1a\u51fa\u9519\uff0c\u4f46\u662f\u4f1a\u5bfc\u81f4\u6587\u4ef6\u5f88\u5927\uff0c\u591a\u5927\uff1f \u662f\u5426\u80fd\u628a\u4e00\u73af\u5883\u5206\u6210\u4e24\u90e8\u5206\uff1f\u4e00\u90e8\u5206\u8f6f\u4ef6\u96c6\u5408\u8d77\u6765\u53d8\u6210\u4e00\u4e2a\u5927\u73af\u5883\uff0c\u53e6\u4e00\u90e8\u5206\u8f6f\u4ef6\u5c31\u7528\u2013use-conda\u73af\u5883\u5355\u72ec\u6307\u5b9a\uff0c\u4f46\u662f\u8fd9\u4e24\u79cd\u65b9\u5f0f\u80fd\u7ed3\u5408\u5230\u4e00\u8d77\u7528\u5417\uff1f # pack cd NGSPipeDB_source_code mamba install -c conda-forge conda-pack conda pack -p ./ngspipedb_py38_conda_env -o ngspipedb_py38_conda_env_osx64.tar.gz # unpack on another machine mkdir -p ngspipedb_py38_conda_env tar -xzf ngspipedb_py38_conda_env_osx64.tar.gz -C ngspipedb_py38_conda_env source activate ./ngspipedb_py38_conda_env conda-unpack conda config \u2013add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config \u2013add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config \u2013add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ conda config \u2013add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/ activate base and set miniconda path conda init Conda Prompt Customization conda config \u2013set env_prompt '({name}) ' source ~/.bashrc update conda, (optional) conda update conda create conda visual environment, python version, snakemake version, env directory,django version conda create -p ngspipedb_py38_conda_env python=3.8 activate conda env conda activate ./ngspipedb_py38_conda_env install mamba to make install software faster. conda install mamba -c conda-forge update some bioinformatics tools we will use bellow. mamba env update \u2013prefix ./ngspipedb_py38_conda_env/ \u2013file requirement.yaml \u2013prune you can exit virtual environment by conda deactivate https://wooey.readthedocs.io/en/latest/install.html \u2013conda-frontend mamba \u9009\u62e9\u66f4\u5feb\u4e00\u70b9\u7684mamba \u2013conda-create-envs-only \u53ea\u521b\u5efa\u73af\u5883\uff0c\u7136\u540e\u9000\u51fa\uff0c\u4e0d\u8fd0\u884c\u7a0b\u5e8f\uff0c\u8fd9\u4e2a\u53ef\u4ee5\u7528\u6765\u4e13\u95e8\u6d4b\u8bd5\u73af\u5883 mac\u4e0a\u7684conda\u73af\u5883\u597d\u50cf\u6ca1\u6709linux\u4e0a\u9762\u90a3\u4e48\u597d\u7528\uff0c\u7279\u522b\u662fanaconda\u521b\u5efa\u7684\u73af\u5883 \u2013conda-prefix \u6307\u5b9aconda\u73af\u5883\u5b89\u88c5\u5730\u5740 \u6e05\u7406conda\u5b89\u88c5\u5305\u548c\u7f13\u5b58 snakemake -s ngspipe/db_generate.Snakefile.py \u2013use-conda \u2013conda-prefix condaEnvSplit -p -j1 Simplest is just abandon the \u2013use-conda flag, as suggested in the answer. Alternatively, you could make a container that has the env pre-created and configured, then use \u2013use-singularity. Or, if the post-installation can be automated, one could build a custom Conda package that runs some post-linking scripts. Sorry I seem to have missed your comment! snakemake \u5982\u4f55\u8fd0\u884c\u5355\u4e2a\u7a0b\u5e8f\uff1f\u8fd9\u4e2a\u4e5f\u5f88\u6709\u7528 \u57fa\u56e0\u7684\u547d\u4ee4\uff0c\u50cfdkango\u8fd9\u6837\u7684\u547d\u4ee4\u5728\u5f88\u591arules\u4e2d\u90fd\u6709\uff0c\u6240\u6709\u6bd4\u5982\u6709\u4e2a\u9876\u5c42\u7684\u73af\u5883\u4e2d\u5b89\u88c5\u4e86django","title":"Reproducibility "},{"location":"NGSPipeDb/#troubleshooting","text":"Ngsdb.yaml+wooey Python=3.8 samtools clustergrammer Pip install wooey pip install pandas==0.25.3","title":"Troubleshooting "},{"location":"NGSPipeDb/#contributing","text":"Please submit an issue to report bugs or ask questions. Please contribute bug fixes or new features with a pull request to this repository. If this does not help, please feel free to consult: * Xuan Zhang ( zhangxuan@xtbg.ac.cn ) or","title":"Contributing"},{"location":"Reference-based-NGSPipe-RNA-seq/","text":"Reference-base RNA-seq analysis use NGSPipe Info If this is your first time using NGSPipe, then we strongly recommend that you start by running test data. If you already have experience with NGSPipe, we suggest you can go straight to the custom data section. Reference genome-based - an assembled genome exists for a species for which an RNAseq experiment is performed. It allows reads to be aligned against the reference genome and significantly improves our ability to reconstruct transcripts. A typical flow of transcriptome analysis with reference is shown in the figure below Quick Start - RNA-Seq analysis on test data 1. Download test files NGSPipe is dependent on reference files and raw sequence reads which can be found in http://www.liu-lab.com/ngspipedb/testdata . To download the mouse RNA-seq test data into ./test_pipeline . ngspipedb download -n ngspipe-rnaseq-basic -t testdata -d test_pipeline cd test_pipeline tar -zxvf testdata-ngspipe-rnaseq-basic.tar.gz cd .. # -n pipeline name # -t data type # ngspipedb download -h for help Make sure you have the following directory structure by command tree test_pipeline : testdata_ngspipe-rnaseq-basic \u251c\u2500\u2500 genome \u2502 \u251c\u2500\u2500 GRCm38.83.chr19.gtf \u2502 \u2514\u2500\u2500 chr19.fa \u2514\u2500\u2500 rawdata \u251c\u2500\u2500 condition.csv \u251c\u2500\u2500 control-0_R1.fq.gz \u251c\u2500\u2500 control-0_R2.fq.gz \u251c\u2500\u2500 control-1_R1.fq.gz \u251c\u2500\u2500 control-1_R2.fq.gz \u251c\u2500\u2500 control-2_R1.fq.gz \u251c\u2500\u2500 control-2_R2.fq.gz \u251c\u2500\u2500 sample.csv \u251c\u2500\u2500 treated-0_R1.fq.gz \u251c\u2500\u2500 treated-0_R2.fq.gz \u251c\u2500\u2500 treated-1_R1.fq.gz \u251c\u2500\u2500 treated-1_R2.fq.gz \u251c\u2500\u2500 treated-2_R1.fq.gz \u2514\u2500\u2500 treated-2_R2.fq.gz 2 directories, 16 files Warning The test data is only used to verify that the analytical process is working properly and the analysis results do not have a biological significance. 2. Run RNA-seq analysis on test data We provied a basic reference-based RNA-seq workflow for users to take a glance of NGSPipe. This workflow contains 7 steps: 1. sampling data (choose part of your data) 2. raw reads qc 3. junction align to genome 4. transcript assembly 5. gene quantification 6. statistic 7. differential gene analysis You can do RNA-seq analysis by just one simply command. ngspipedb runpipe ngspipe-rnaseq-basic -n ngspipe-rnaseq-basic -d test_pipeline --genomeFasta testdata_ngspipe-rnaseq-basic/genome/chr19.fa --genomeAnno testdata_ngspipe-rnaseq-basic/genome/GRCm38.83.chr19.gtf --samplefile testdata_ngspipe-rnaseq-basic/rawdata/sample.csv --conditionfile testdata_ngspipe-rnaseq-basic/rawdata/condition.csv --rawreadsdir testdata_ngspipe-rnaseq-basic/rawdata --snaketype p --report -db -ps The final data files are put in the folder test_pipeline/ngspipe-rnaseq-basic . Please check you result file tree -d -L 2 test_pipeline/ngspipe-rnaseq-basic , it may like this: test_pipeline/ngspipe-rnaseq-basic \u251c\u2500\u2500 database \u251c\u2500\u2500 genome \u251c\u2500\u2500 rawdata \u2514\u2500\u2500 result_Sep-06-2021 \u251c\u2500\u2500 ngsdb_code \u2502 \u251c\u2500\u2500 __pycache__ \u2502 \u251c\u2500\u2500 blastplus \u2502 \u251c\u2500\u2500 geneAnno \u2502 \u251c\u2500\u2500 geneDetail \u2502 \u251c\u2500\u2500 geneExpAtlas \u2502 \u251c\u2500\u2500 home \u2502 \u251c\u2500\u2500 igv \u2502 \u251c\u2500\u2500 media \u2502 \u251c\u2500\u2500 ngsdb \u2502 \u251c\u2500\u2500 search \u2502 \u251c\u2500\u2500 tools \u2502 \u2514\u2500\u2500 wooey \u251c\u2500\u2500 ngsdb_data \u2502 \u251c\u2500\u2500 addscript \u2502 \u251c\u2500\u2500 blastdb \u2502 \u251c\u2500\u2500 exp \u2502 \u251c\u2500\u2500 gbrowse \u2502 \u251c\u2500\u2500 gff_sqlite3 \u2502 \u2514\u2500\u2500 migration \u251c\u2500\u2500 ngspipe_result \u2502 \u251c\u2500\u2500 diff \u2502 \u251c\u2500\u2500 mapping \u2502 \u251c\u2500\u2500 quantify \u2502 \u251c\u2500\u2500 rawReads_qc \u2502 \u251c\u2500\u2500 sampling_data \u2502 \u2514\u2500\u2500 statistic \u2514\u2500\u2500 report \u251c\u2500\u2500 1.pipeline \u251c\u2500\u2500 2.rawreads_stat \u251c\u2500\u2500 3.cleanreads_stat \u251c\u2500\u2500 4.mapping_stat \u2514\u2500\u2500 5.exp_stat 37 directories Note If you encounter any problem in this step, please turn to TroubleShooting for help.","title":"NGSPipe Reference-based RNA-seq"},{"location":"Reference-based-NGSPipe-RNA-seq/#reference-base-rna-seq-analysis-use-ngspipe","text":"","title":"Reference-base RNA-seq analysis use NGSPipe"},{"location":"Reference-based-NGSPipe-RNA-seq/#_1","text":"Info If this is your first time using NGSPipe, then we strongly recommend that you start by running test data. If you already have experience with NGSPipe, we suggest you can go straight to the custom data section. Reference genome-based - an assembled genome exists for a species for which an RNAseq experiment is performed. It allows reads to be aligned against the reference genome and significantly improves our ability to reconstruct transcripts. A typical flow of transcriptome analysis with reference is shown in the figure below","title":""},{"location":"Reference-based-NGSPipe-RNA-seq/#quick-start-rna-seq-analysis-on-test-data","text":"","title":"Quick Start - RNA-Seq analysis on test data "},{"location":"Reference-based-NGSPipe-RNA-seq/#1-download-test-files","text":"NGSPipe is dependent on reference files and raw sequence reads which can be found in http://www.liu-lab.com/ngspipedb/testdata . To download the mouse RNA-seq test data into ./test_pipeline . ngspipedb download -n ngspipe-rnaseq-basic -t testdata -d test_pipeline cd test_pipeline tar -zxvf testdata-ngspipe-rnaseq-basic.tar.gz cd .. # -n pipeline name # -t data type # ngspipedb download -h for help Make sure you have the following directory structure by command tree test_pipeline : testdata_ngspipe-rnaseq-basic \u251c\u2500\u2500 genome \u2502 \u251c\u2500\u2500 GRCm38.83.chr19.gtf \u2502 \u2514\u2500\u2500 chr19.fa \u2514\u2500\u2500 rawdata \u251c\u2500\u2500 condition.csv \u251c\u2500\u2500 control-0_R1.fq.gz \u251c\u2500\u2500 control-0_R2.fq.gz \u251c\u2500\u2500 control-1_R1.fq.gz \u251c\u2500\u2500 control-1_R2.fq.gz \u251c\u2500\u2500 control-2_R1.fq.gz \u251c\u2500\u2500 control-2_R2.fq.gz \u251c\u2500\u2500 sample.csv \u251c\u2500\u2500 treated-0_R1.fq.gz \u251c\u2500\u2500 treated-0_R2.fq.gz \u251c\u2500\u2500 treated-1_R1.fq.gz \u251c\u2500\u2500 treated-1_R2.fq.gz \u251c\u2500\u2500 treated-2_R1.fq.gz \u2514\u2500\u2500 treated-2_R2.fq.gz 2 directories, 16 files Warning The test data is only used to verify that the analytical process is working properly and the analysis results do not have a biological significance.","title":"1. Download test files "},{"location":"Reference-based-NGSPipe-RNA-seq/#2-run-rna-seq-analysis-on-test-data","text":"We provied a basic reference-based RNA-seq workflow for users to take a glance of NGSPipe. This workflow contains 7 steps: 1. sampling data (choose part of your data) 2. raw reads qc 3. junction align to genome 4. transcript assembly 5. gene quantification 6. statistic 7. differential gene analysis You can do RNA-seq analysis by just one simply command. ngspipedb runpipe ngspipe-rnaseq-basic -n ngspipe-rnaseq-basic -d test_pipeline --genomeFasta testdata_ngspipe-rnaseq-basic/genome/chr19.fa --genomeAnno testdata_ngspipe-rnaseq-basic/genome/GRCm38.83.chr19.gtf --samplefile testdata_ngspipe-rnaseq-basic/rawdata/sample.csv --conditionfile testdata_ngspipe-rnaseq-basic/rawdata/condition.csv --rawreadsdir testdata_ngspipe-rnaseq-basic/rawdata --snaketype p --report -db -ps The final data files are put in the folder test_pipeline/ngspipe-rnaseq-basic . Please check you result file tree -d -L 2 test_pipeline/ngspipe-rnaseq-basic , it may like this: test_pipeline/ngspipe-rnaseq-basic \u251c\u2500\u2500 database \u251c\u2500\u2500 genome \u251c\u2500\u2500 rawdata \u2514\u2500\u2500 result_Sep-06-2021 \u251c\u2500\u2500 ngsdb_code \u2502 \u251c\u2500\u2500 __pycache__ \u2502 \u251c\u2500\u2500 blastplus \u2502 \u251c\u2500\u2500 geneAnno \u2502 \u251c\u2500\u2500 geneDetail \u2502 \u251c\u2500\u2500 geneExpAtlas \u2502 \u251c\u2500\u2500 home \u2502 \u251c\u2500\u2500 igv \u2502 \u251c\u2500\u2500 media \u2502 \u251c\u2500\u2500 ngsdb \u2502 \u251c\u2500\u2500 search \u2502 \u251c\u2500\u2500 tools \u2502 \u2514\u2500\u2500 wooey \u251c\u2500\u2500 ngsdb_data \u2502 \u251c\u2500\u2500 addscript \u2502 \u251c\u2500\u2500 blastdb \u2502 \u251c\u2500\u2500 exp \u2502 \u251c\u2500\u2500 gbrowse \u2502 \u251c\u2500\u2500 gff_sqlite3 \u2502 \u2514\u2500\u2500 migration \u251c\u2500\u2500 ngspipe_result \u2502 \u251c\u2500\u2500 diff \u2502 \u251c\u2500\u2500 mapping \u2502 \u251c\u2500\u2500 quantify \u2502 \u251c\u2500\u2500 rawReads_qc \u2502 \u251c\u2500\u2500 sampling_data \u2502 \u2514\u2500\u2500 statistic \u2514\u2500\u2500 report \u251c\u2500\u2500 1.pipeline \u251c\u2500\u2500 2.rawreads_stat \u251c\u2500\u2500 3.cleanreads_stat \u251c\u2500\u2500 4.mapping_stat \u2514\u2500\u2500 5.exp_stat 37 directories Note If you encounter any problem in this step, please turn to TroubleShooting for help.","title":"2. Run RNA-seq analysis on test data "},{"location":"Reference-free-NGSPipe-RNA-seq/","text":"Reference-free RNA-seq analysis use NGSPipe Info If this is your first time using NGSPipe, then we strongly recommend that you start by running test data. If you already have experience with NGSPipe, we suggest you can go straight to the custom data section. Reference genome-free - no genome assembly for the species of interest is available. In this case one would need to assemble the reads into transcripts using de novo approaches. This type of RNAseq is as much of an art as well as science because assembly is heavily parameter-dependent and difficult to do well. In this lesson we will focus on the Reference genome-based type of RNA seq. A typical flow of transcriptome analysis with reference is shown in the figure below Quick Start - One time installation of components necessary for RNA-Seq analysis on test data","title":"NGSPipe Denovo RNA-seq"},{"location":"Reference-free-NGSPipe-RNA-seq/#reference-free-rna-seq-analysis-use-ngspipe","text":"","title":"Reference-free RNA-seq analysis use NGSPipe"},{"location":"Reference-free-NGSPipe-RNA-seq/#_1","text":"Info If this is your first time using NGSPipe, then we strongly recommend that you start by running test data. If you already have experience with NGSPipe, we suggest you can go straight to the custom data section. Reference genome-free - no genome assembly for the species of interest is available. In this case one would need to assemble the reads into transcripts using de novo approaches. This type of RNAseq is as much of an art as well as science because assembly is heavily parameter-dependent and difficult to do well. In this lesson we will focus on the Reference genome-based type of RNA seq. A typical flow of transcriptome analysis with reference is shown in the figure below","title":""},{"location":"Reference-free-NGSPipe-RNA-seq/#quick-start-one-time-installation-of-components-necessary-for-rna-seq-analysis-on-test-data","text":"","title":"Quick Start - One time installation of components necessary for RNA-Seq analysis on test data "},{"location":"changelog/","text":"Change logs [0.0.4] - 2021-5-9 all gtf/gff files need to be repaired by agat report updated, added more details about method, added more plot by bioinfokit , such as PCA plot, Volcano Plot, and sample cluster plot add denovel rna-seq analysis by trinity update some documents: reference-based rna-seq analysis, conda usage add normalized expression matrix library strand check by resqc reference statistic by agat user need to provide a \"compare file\" to let deseq2 known which two sample will be comapre [0.0.3] - 2021-3-31 fix bugs when deseq2 quit add gene expression value of all samples in deseq2 result [0.0.2] - 2021-3-27 fix some doc error fix \"Error: : syntax error in line 1 near '['\" [0.0.1] - 2021-3-25 fix \"one_step_rnaseq.sh\" run error add notify update function [0.0.0] - 2021-2-1 update ngsdb","title":"Change logs"},{"location":"changelog/#change-logs","text":"","title":"Change logs"},{"location":"changelog/#004-2021-5-9","text":"all gtf/gff files need to be repaired by agat report updated, added more details about method, added more plot by bioinfokit , such as PCA plot, Volcano Plot, and sample cluster plot add denovel rna-seq analysis by trinity update some documents: reference-based rna-seq analysis, conda usage add normalized expression matrix library strand check by resqc reference statistic by agat user need to provide a \"compare file\" to let deseq2 known which two sample will be comapre","title":"[0.0.4] - 2021-5-9"},{"location":"changelog/#003-2021-3-31","text":"fix bugs when deseq2 quit add gene expression value of all samples in deseq2 result","title":"[0.0.3] - 2021-3-31"},{"location":"changelog/#002-2021-3-27","text":"fix some doc error fix \"Error: : syntax error in line 1 near '['\"","title":"[0.0.2] - 2021-3-27"},{"location":"changelog/#001-2021-3-25","text":"fix \"one_step_rnaseq.sh\" run error add notify update function","title":"[0.0.1] - 2021-3-25"},{"location":"changelog/#000-2021-2-1","text":"update ngsdb","title":"[0.0.0] - 2021-2-1"},{"location":"conda/","text":"conda usage download pre-build ngspipe-ranseq env ngspipd-rnaseq-Linux-x86-64 ngspipd-rnaseq-MacOSX-x86-64","title":"conda usage"},{"location":"conda/#conda-usage","text":"","title":"conda usage"},{"location":"conda/#download-pre-build-ngspipe-ranseq-env","text":"ngspipd-rnaseq-Linux-x86-64 ngspipd-rnaseq-MacOSX-x86-64","title":"download pre-build ngspipe-ranseq env "},{"location":"download_sra/","text":"conda create -n sradownload conda activate sradownload mamba install sra-tools=2.10.1 -c bioconda mamba install -y -c hcc aspera-cli=3.9.1","title":"Download sra"},{"location":"linux/","text":"Shell and Linux Author: Hanrui Bai, 2021-2-15 About Linux The complete Linux operating system includes the kernel and outer layer applications. Different Linux distributions use the same kernel and different outer layer applications. Common Linux distributions are Ubuntu , red hat , SuSE , Gentoo , CentOS and Debian . Shell is the interface between the linux kernel and the user. Get Linux Install Ubuntu in a virtual environment. Not suggested to novices. Buy a Ubuntu. Apply for an account at the Institute\u2019s Supercomputer Center. This is the most common method. Log into Linux sever from Windows Download a Secure Shell (ssh) terminal. Common terminal: Xshell: https://www.xshellcn.com/ PuTTY: http://www.putty.org/ Install the shell terminal. Create a new session. Choose the ssh protocol and enter the host IP, port, user ID and password. Click connect . Log into Linux sever from Linux or Mac Type command in terminal: ssh [host IP:port]@[user ID] . Then enter the password. Basic knowledge of Linux The absolute path is identified by a forward slash ( / ), and the structure of directory is tree structure. How to use linux command: enter the command at the shell prompt: $ . Command like: [Path]/command [-option parameter] [file|directory] . For example: ~/miniconda3/envs/RNA/bin/fastp -i /home/sysbio/SRR8467686.fastq.gz Enter a single dot ( . ) to indicate the current directory, and enter a double dot ( .. ) to indicate the parent directory of the current directory. For example: cd .. Use the man command to view the operation manual of all required commands. Command like: man [command name] . For example: man cp Filter: The filter refers to the name of the specified file and is used after many commands. Add a filter after the ls command, then only the information of the file will be displayed. For example: ls -l my_file This command specifies the relevant information of the output file my_file. When writing a filter, you can use a question mark ( ? ) to represent a character, an asterisk ( * ) to represent zero or more characters, and use the tab key ( Tab ) to quickly complete the file name or directory first name. The which command is used to find the path of the command. Command like: which grep For example: which fastp About permission View the file permission When you use ls -l command, the permissions will be marked at the beginning of the file, like: drwxrwxrwx. The first letter represents the type of file: d means directory, - means file, and l means soft link. The remaining nine letters are grouped into three, representing the permissions for the owner, the owner s group, and other groups. r means read-only. w means allowing user to modify the content of the file. x means allowing user to execute the file as a program. - means having no such permission. Modify permissions: chmod command You must have the authority to operate files Command like: chmod (user permissions) (group permissions) (other permissions) file Permission is expressed in octal code: r=4, w=2, x=1 For example: chmod 755 test.txt The result is -rwxr-xr-x test.txt Command about directory Check files which are in the directory list Basic list function: ls command Command like: ls various parameters directory name -F Distinguish between files and directories -R Recursive option to list files in subdirectories contained in the current directory -l Produces a long list of output results, including information about each file -d Lists only the information of the directory itself, not its contents -i The inode number of the file, which is the unique identifier of the file -a Display both hidden files and ordinary files -t Sort by time modified -h Show file size easy to read for human The parameters can be combined and written. For example: ls -ltrh . The way to output the tree list: tree tool The tool needs to be installed by yourself. Command like: tree ./ . Create a directory: mkdir command Command like: mkdir [directory name] To create multiple directories and subdirectories, you can use the -p parameter. For example: mkdir -p New_file/work/file1 . The -p parameter in the mkdir command can create missing parent directories as needed. Delete directory: rmdir command Command like: rmdir [-option parameter] [directory name] - -No Parameters after rmdir delete empty directories - -rf Delete all contents in the directory - -i Ask a question before deleting Because Linux does not have a recycle bin, you must add the -i parameter when deleting to confirm whether the deleted content is correct. Switch the directory: cd command Command like: cd directory For example: cd /usr/bin View the current absolute path of current directory Command like: pwd Command about file Create a file: touch command Command like: touch [-option parameter] [file name] - Create a new file without adding parameters after touch, if the file already exists, change the modification time. - -a Change the access time of an existing file Delete files: rm command Command like: rm -i [file name] Because Linux does not have a recycle bin, you must add the -i parameter to avoid errors when deleting. Copy files: cp command Command like: cp [-option parameter] [file name] - -i Force to ask if you need to overwrite existing files - -R Copy the entire directory recursively To avoid errors, it is recommended to add the -i parameter Rename and move files: mv command Rename Command like: mv [original file name] [new file name] Move Command like: mv [file name in the original path] [target new path] Rename and move operations can be performed at the same time For example: mv /home/picture/book /home/file/cook . Move the book file in the picture folder to the file folder, and rename it to cook . View files View file type: file command Command like: file [file name] You can check the file type, character encoding method, whether the file can be run, etc. View the entire file content cat command: display all data in the text file Command like: cat [-option parameter] [file name] No parameters after cat means display content. -n Display content after adding line number. -b Displays only after adding line numbers to text content. -T Does not display tabs, replace tabs with ^T to display. more command: display the content of the text file, but it will stop after each page is displayed. less command: display the content of text files and support more advanced interaction. View a part of file content head command: view the beginning of the file Command like: head -n file name n is the number of rows displayed tail command: view the end of the file Command like: tail -n file name n is the number of rows displayed Upload files, download files rz : upload file sz [file name] : download file Command about process Probe the process ps command command like: ps [-option parameter] Symbol description: PID : Process ID. TTY : Terminal device when process starts. TIME : Cumulative CPU time required by the process. CMD : The name of the command used. top command Command like: top Symbol description: load average : The three values are the average load of the last 1min, 5min, and 15min. The larger the value, the larger the load, and the more than 2 indicates the system is busy. PR : Process priority NI : Moderate value of process VIRT : The total amount of virtual memory occupied by the process RES : The total amount of physical memory occupied by process. MEM : The ratio of memory used by the process to available memory. S : Process state ( D : interruptible sleep state; R : running; S : sleeping; T : tracking or stopping state; Z : rigid state). The difference between ps and top command The ps command displays information at a specific time point, and the top command displays real-time information. End the process kill command command like: kill PID or kill -s [process signal] killall command Command like: killall [process name] Use wildcards carefully in the killall command Command about task Execute tasks to the background [Path]/command [-option parameter] [file|directory] & nohup [path]/command [-option parameter] [file|directory] & screen command, command like : Create a screen: screen -dmS screen_test View the screen: screen -list Connect to the screen: screen -r screen_test Common task management commands: jobs : View tasks, return task number n and process number bg %n : Transfer task number n to the background fg %n : Transfer task number n to the foreground ctrl+z : Suspend the current task ctrl+c : Stop the current task kill -n task : End the task Command about disk space Mount the device: mount command Command like: mount parameter file device type device to be mounted target location File device types are: - -vfat : Windows long file system - -ntfs : An advanced file system widely used in Windows - -iso9660 : Standard CD-ROM file system Uninstall the device: umount command Command like: umount location/target device Explore the disk situation df command Command like: df [-option parameter] [target disk] du command Command like: du [-option parameter] [target disk] -c Displays the total size of all listed files -h Display in a user-readable way -s Displays the total of each output parameter The difference between df and du commands The df command displays the disk usage, the du command displays the disk usage of each file Disk partition: fdisk command Command like: fdisk -l [disk name] Disk formatting: mkfs command Command like: mksf -t file [system format] [-option parameter] [disk name] File system formats are: mkfs.cramfs, mkfs.ext2, mkfs.ext3, mkfs.msdos, mkfs.vfat Disk verification: fsck command Command like: fsck -t file [system format] [-option parameter] [disk name] File system formats are: fsck.cramfs, fsck.ext2, fsck.ext3, fsck.msdos, fsck.vfat Bioinformatics on linux cases 1: install software Download software: wget \u2013c ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/ncbi-blast-2.6.0+-x64-linux.tar.gz Unzip file: tar zxvf ncbi-blast-2.6.0+-x64-linux.tar.gz Install the software: cd soft ./configure make make install Update PATH: Add the ./ncbi-blast-2.6.0+/bin directory to the environment variables: vim ~/.bashrc Add the following statement, save and exit: export PATH=./ncbi-blast-2.6.0+/bin:$PATH Update environment variables: source ~/.bashrc 2: download data from database wget command Command like: wget [-option parameter] [URL] -c When connection has been cut off,you can use this parameter to resume the transfer. -i When there are multiple files to download, you can write the URL of each file in a download.txt. Then type command: wget -i download.txt . -r Download all files from this website including all addresses pointed to by the site. For example: wget [https://www.ncbi.nlm.nih.gov/sra/SRR8467693](https://www.ncbi.nlm.nih.gov/sra/SRR8467693) sratoolkit Install sratoolkit Write command like: module load sratoolkit prefetch SRR8467686 3: fastq-dump Command like: fastq-dump [-option parameter] - --split-spot : Split paired-end sequencing into two copies, but put them in the same file - --split-files : Divide paired-end sequencing into two copies and put them in different files, but discard the reads that one party has but one does not. - --split-3 : Divide the paired-end sequencing into two copies and put them in different files, but the reads that one party has and the other does not will be put in a separate folder - -o Output path","title":"Shell and Linux"},{"location":"linux/#shell-and-linux","text":"Author: Hanrui Bai, 2021-2-15","title":"Shell and Linux"},{"location":"linux/#about-linux","text":"The complete Linux operating system includes the kernel and outer layer applications. Different Linux distributions use the same kernel and different outer layer applications. Common Linux distributions are Ubuntu , red hat , SuSE , Gentoo , CentOS and Debian . Shell is the interface between the linux kernel and the user.","title":"About Linux"},{"location":"linux/#get-linux","text":"Install Ubuntu in a virtual environment. Not suggested to novices. Buy a Ubuntu. Apply for an account at the Institute\u2019s Supercomputer Center. This is the most common method.","title":"Get Linux"},{"location":"linux/#log-into-linux-sever-from-windows","text":"Download a Secure Shell (ssh) terminal. Common terminal: Xshell: https://www.xshellcn.com/ PuTTY: http://www.putty.org/ Install the shell terminal. Create a new session. Choose the ssh protocol and enter the host IP, port, user ID and password. Click connect .","title":"Log into Linux sever from Windows"},{"location":"linux/#log-into-linux-sever-from-linux-or-mac","text":"Type command in terminal: ssh [host IP:port]@[user ID] . Then enter the password.","title":"Log into Linux sever from Linux or Mac"},{"location":"linux/#basic-knowledge-of-linux","text":"The absolute path is identified by a forward slash ( / ), and the structure of directory is tree structure. How to use linux command: enter the command at the shell prompt: $ . Command like: [Path]/command [-option parameter] [file|directory] . For example: ~/miniconda3/envs/RNA/bin/fastp -i /home/sysbio/SRR8467686.fastq.gz Enter a single dot ( . ) to indicate the current directory, and enter a double dot ( .. ) to indicate the parent directory of the current directory. For example: cd .. Use the man command to view the operation manual of all required commands. Command like: man [command name] . For example: man cp Filter: The filter refers to the name of the specified file and is used after many commands. Add a filter after the ls command, then only the information of the file will be displayed. For example: ls -l my_file This command specifies the relevant information of the output file my_file. When writing a filter, you can use a question mark ( ? ) to represent a character, an asterisk ( * ) to represent zero or more characters, and use the tab key ( Tab ) to quickly complete the file name or directory first name. The which command is used to find the path of the command. Command like: which grep For example: which fastp","title":"Basic knowledge of Linux"},{"location":"linux/#about-permission","text":"","title":"About permission"},{"location":"linux/#view-the-file-permission","text":"When you use ls -l command, the permissions will be marked at the beginning of the file, like: drwxrwxrwx. The first letter represents the type of file: d means directory, - means file, and l means soft link. The remaining nine letters are grouped into three, representing the permissions for the owner, the owner s group, and other groups. r means read-only. w means allowing user to modify the content of the file. x means allowing user to execute the file as a program. - means having no such permission.","title":"View the file permission"},{"location":"linux/#modify-permissions-chmod-command","text":"You must have the authority to operate files Command like: chmod (user permissions) (group permissions) (other permissions) file Permission is expressed in octal code: r=4, w=2, x=1 For example: chmod 755 test.txt The result is -rwxr-xr-x test.txt","title":"Modify permissions: chmod command"},{"location":"linux/#command-about-directory","text":"","title":"Command about directory"},{"location":"linux/#check-files-which-are-in-the-directory-list","text":"Basic list function: ls command Command like: ls various parameters directory name -F Distinguish between files and directories -R Recursive option to list files in subdirectories contained in the current directory -l Produces a long list of output results, including information about each file -d Lists only the information of the directory itself, not its contents -i The inode number of the file, which is the unique identifier of the file -a Display both hidden files and ordinary files -t Sort by time modified -h Show file size easy to read for human The parameters can be combined and written. For example: ls -ltrh . The way to output the tree list: tree tool The tool needs to be installed by yourself. Command like: tree ./ .","title":"Check files which are in the directory list"},{"location":"linux/#create-a-directory-mkdir-command","text":"Command like: mkdir [directory name] To create multiple directories and subdirectories, you can use the -p parameter. For example: mkdir -p New_file/work/file1 . The -p parameter in the mkdir command can create missing parent directories as needed.","title":"Create a directory: mkdir command"},{"location":"linux/#delete-directory-rmdir-command","text":"Command like: rmdir [-option parameter] [directory name] - -No Parameters after rmdir delete empty directories - -rf Delete all contents in the directory - -i Ask a question before deleting Because Linux does not have a recycle bin, you must add the -i parameter when deleting to confirm whether the deleted content is correct.","title":"Delete directory: rmdir command"},{"location":"linux/#switch-the-directory-cd-command","text":"Command like: cd directory For example: cd /usr/bin","title":"Switch the directory: cd command"},{"location":"linux/#view-the-current-absolute-path-of-current-directory","text":"Command like: pwd","title":"View the current absolute path of current directory"},{"location":"linux/#command-about-file","text":"","title":"Command about file"},{"location":"linux/#create-a-file-touch-command","text":"Command like: touch [-option parameter] [file name] - Create a new file without adding parameters after touch, if the file already exists, change the modification time. - -a Change the access time of an existing file","title":"Create a file: touch command"},{"location":"linux/#delete-files-rm-command","text":"Command like: rm -i [file name] Because Linux does not have a recycle bin, you must add the -i parameter to avoid errors when deleting.","title":"Delete files: rm command"},{"location":"linux/#copy-files-cp-command","text":"Command like: cp [-option parameter] [file name] - -i Force to ask if you need to overwrite existing files - -R Copy the entire directory recursively To avoid errors, it is recommended to add the -i parameter","title":"Copy files: cp command"},{"location":"linux/#rename-and-move-files-mv-command","text":"Rename Command like: mv [original file name] [new file name] Move Command like: mv [file name in the original path] [target new path] Rename and move operations can be performed at the same time For example: mv /home/picture/book /home/file/cook . Move the book file in the picture folder to the file folder, and rename it to cook .","title":"Rename and move files: mv command"},{"location":"linux/#view-files","text":"","title":"View files"},{"location":"linux/#view-file-type-file-command","text":"Command like: file [file name] You can check the file type, character encoding method, whether the file can be run, etc.","title":"View file type: file command"},{"location":"linux/#view-the-entire-file-content","text":"cat command: display all data in the text file Command like: cat [-option parameter] [file name] No parameters after cat means display content. -n Display content after adding line number. -b Displays only after adding line numbers to text content. -T Does not display tabs, replace tabs with ^T to display. more command: display the content of the text file, but it will stop after each page is displayed. less command: display the content of text files and support more advanced interaction.","title":"View the entire file content"},{"location":"linux/#view-a-part-of-file-content","text":"head command: view the beginning of the file Command like: head -n file name n is the number of rows displayed tail command: view the end of the file Command like: tail -n file name n is the number of rows displayed","title":"View a part of file content"},{"location":"linux/#upload-files-download-files","text":"rz : upload file sz [file name] : download file","title":"Upload files, download files"},{"location":"linux/#command-about-process","text":"","title":"Command about process"},{"location":"linux/#probe-the-process","text":"ps command command like: ps [-option parameter] Symbol description: PID : Process ID. TTY : Terminal device when process starts. TIME : Cumulative CPU time required by the process. CMD : The name of the command used. top command Command like: top Symbol description: load average : The three values are the average load of the last 1min, 5min, and 15min. The larger the value, the larger the load, and the more than 2 indicates the system is busy. PR : Process priority NI : Moderate value of process VIRT : The total amount of virtual memory occupied by the process RES : The total amount of physical memory occupied by process. MEM : The ratio of memory used by the process to available memory. S : Process state ( D : interruptible sleep state; R : running; S : sleeping; T : tracking or stopping state; Z : rigid state). The difference between ps and top command The ps command displays information at a specific time point, and the top command displays real-time information.","title":"Probe the process"},{"location":"linux/#end-the-process","text":"kill command command like: kill PID or kill -s [process signal] killall command Command like: killall [process name] Use wildcards carefully in the killall command","title":"End the process"},{"location":"linux/#command-about-task","text":"","title":"Command about task"},{"location":"linux/#execute-tasks-to-the-background","text":"[Path]/command [-option parameter] [file|directory] & nohup [path]/command [-option parameter] [file|directory] & screen command, command like : Create a screen: screen -dmS screen_test View the screen: screen -list Connect to the screen: screen -r screen_test","title":"Execute tasks to the background"},{"location":"linux/#common-task-management-commands","text":"jobs : View tasks, return task number n and process number bg %n : Transfer task number n to the background fg %n : Transfer task number n to the foreground ctrl+z : Suspend the current task ctrl+c : Stop the current task kill -n task : End the task","title":"Common task management commands:"},{"location":"linux/#command-about-disk-space","text":"","title":"Command about disk space"},{"location":"linux/#mount-the-device-mount-command","text":"Command like: mount parameter file device type device to be mounted target location File device types are: - -vfat : Windows long file system - -ntfs : An advanced file system widely used in Windows - -iso9660 : Standard CD-ROM file system","title":"Mount the device: mount command"},{"location":"linux/#uninstall-the-device-umount-command","text":"Command like: umount location/target device","title":"Uninstall the device: umount command"},{"location":"linux/#explore-the-disk-situation","text":"df command Command like: df [-option parameter] [target disk] du command Command like: du [-option parameter] [target disk] -c Displays the total size of all listed files -h Display in a user-readable way -s Displays the total of each output parameter The difference between df and du commands The df command displays the disk usage, the du command displays the disk usage of each file Disk partition: fdisk command Command like: fdisk -l [disk name] Disk formatting: mkfs command Command like: mksf -t file [system format] [-option parameter] [disk name] File system formats are: mkfs.cramfs, mkfs.ext2, mkfs.ext3, mkfs.msdos, mkfs.vfat Disk verification: fsck command Command like: fsck -t file [system format] [-option parameter] [disk name] File system formats are: fsck.cramfs, fsck.ext2, fsck.ext3, fsck.msdos, fsck.vfat","title":"Explore the disk situation"},{"location":"linux/#bioinformatics-on-linux-cases","text":"","title":"Bioinformatics on linux cases"},{"location":"linux/#1-install-software","text":"Download software: wget \u2013c ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/ncbi-blast-2.6.0+-x64-linux.tar.gz Unzip file: tar zxvf ncbi-blast-2.6.0+-x64-linux.tar.gz Install the software: cd soft ./configure make make install Update PATH: Add the ./ncbi-blast-2.6.0+/bin directory to the environment variables: vim ~/.bashrc Add the following statement, save and exit: export PATH=./ncbi-blast-2.6.0+/bin:$PATH Update environment variables: source ~/.bashrc","title":"1: install software"},{"location":"linux/#2-download-data-from-database","text":"wget command Command like: wget [-option parameter] [URL] -c When connection has been cut off,you can use this parameter to resume the transfer. -i When there are multiple files to download, you can write the URL of each file in a download.txt. Then type command: wget -i download.txt . -r Download all files from this website including all addresses pointed to by the site. For example: wget [https://www.ncbi.nlm.nih.gov/sra/SRR8467693](https://www.ncbi.nlm.nih.gov/sra/SRR8467693) sratoolkit Install sratoolkit Write command like: module load sratoolkit prefetch SRR8467686","title":"2: download data from database"},{"location":"linux/#3-fastq-dump","text":"Command like: fastq-dump [-option parameter] - --split-spot : Split paired-end sequencing into two copies, but put them in the same file - --split-files : Divide paired-end sequencing into two copies and put them in different files, but discard the reads that one party has but one does not. - --split-3 : Divide the paired-end sequencing into two copies and put them in different files, but the reads that one party has and the other does not will be put in a separate folder - -o Output path","title":"3: fastq-dump"},{"location":"ngs/","text":"NGS analysis Table of Contents: RNASeq ChipSeq RNA-Seq analysis Chip-Seq analysis","title":"NGS analysis"},{"location":"ngs/#ngs-analysis","text":"Table of Contents: RNASeq ChipSeq","title":"NGS analysis"},{"location":"ngs/#rna-seq-analysis","text":"","title":"RNA-Seq analysis "},{"location":"ngs/#chip-seq-analysis","text":"","title":"Chip-Seq analysis "},{"location":"todo/","text":"todo RNA-Seq gene.csv need normalized fix one time run ranseq 1.2 rnaseq 1.3 ngsdb search ngsdb tools + seq cut report slow add all sample's gene expression in differential expression analysis repair gff first predict adapter by minion library strand by resqc become a conda package \u8981\u6c42\u7528\u6237\u63d0\u4f9b\u57fa\u56e0\u6ce8\u91ca\u6587\u4ef6 gff repair denovo rna-seq become a conda package differential visualization go kegg enrichment analysis docs markdown task list report add bioinfokit package update expression plot package ngspipe rnaseq ref ngspipe rnaseq denovo ngspipe chipseq tf ngsdb \u63d0\u4ea4\u591a\u4e2a\u57fa\u56e0\uff0c\u5f97\u5230\u8868\u8fbe\u91cf\uff0c\u505ago\u5bcc\u96c6 \u6279\u91cf\u63d0\u4ea4\u641c\u7d22\u5f88\u91cd\u8981 \u8868\u8fbe\u91cf\u9875\u9762\uff0c\u7b5b\u9009\u51fa\u6765\u7684\u57fa\u56e0\uff0c\u8df3\u8f6c\u5230tools\u6307\u5b9a\u529f\u80fd \u6dfb\u52a0download\u9875\u9762 diff \u63d0\u4f9b\u8c01\u8ddf\u8c01\u6bd4","title":"Todo"},{"location":"todo/#todo","text":"","title":"todo"},{"location":"todo/#rna-seq","text":"gene.csv need normalized fix one time run ranseq 1.2 rnaseq 1.3 ngsdb search ngsdb tools + seq cut report slow add all sample's gene expression in differential expression analysis repair gff first predict adapter by minion library strand by resqc become a conda package \u8981\u6c42\u7528\u6237\u63d0\u4f9b\u57fa\u56e0\u6ce8\u91ca\u6587\u4ef6 gff repair denovo rna-seq become a conda package differential visualization go kegg enrichment analysis","title":"RNA-Seq"},{"location":"todo/#docs","text":"markdown task list","title":"docs"},{"location":"todo/#report","text":"add bioinfokit package update expression plot","title":"report"},{"location":"todo/#package","text":"ngspipe rnaseq ref ngspipe rnaseq denovo ngspipe chipseq tf ngsdb \u63d0\u4ea4\u591a\u4e2a\u57fa\u56e0\uff0c\u5f97\u5230\u8868\u8fbe\u91cf\uff0c\u505ago\u5bcc\u96c6 \u6279\u91cf\u63d0\u4ea4\u641c\u7d22\u5f88\u91cd\u8981 \u8868\u8fbe\u91cf\u9875\u9762\uff0c\u7b5b\u9009\u51fa\u6765\u7684\u57fa\u56e0\uff0c\u8df3\u8f6c\u5230tools\u6307\u5b9a\u529f\u80fd \u6dfb\u52a0download\u9875\u9762 diff \u63d0\u4f9b\u8c01\u8ddf\u8c01\u6bd4","title":"package"}]}